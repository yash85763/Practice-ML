{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b9b9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "mpl.rcParams['figure.dpi']=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7bf2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model(\n",
    "    num_layers=1,\n",
    "    architecture=[32],\n",
    "    act_func=\"relu\",\n",
    "    input_shape=(28, 28),\n",
    "    dropout = 0.1,\n",
    "    output_bias = None,\n",
    "    output_class=10):\n",
    "    \"\"\"\n",
    "  Builds a densely connected neural network model from user input\n",
    "  \n",
    "  Arguments\n",
    "          num_layers: Number of hidden layers\n",
    "          architecture: Architecture of the hidden layers (densely connected)\n",
    "          act_func: Activation function. Could be 'relu', 'sigmoid', or 'tanh'.\n",
    "          input_shape: Dimension of the input vector\n",
    "          output_class: Number of classes in the output vector\n",
    "  Returns\n",
    "          A neural net (Keras) model for classification\n",
    "    \"\"\"\n",
    "    layers = [tf.keras.layers.Flatten(input_shape=input_shape)]\n",
    "    if act_func == \"relu\":\n",
    "        activation = tf.nn.relu\n",
    "    elif act_func == \"sigmoid\":\n",
    "        activation = tf.nn.sigmoid\n",
    "    elif act_func == \"tanh\":\n",
    "        activation = tf.nn.tanh\n",
    "\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        layers.append(tf.keras.layers.Dense(architecture[i], activation=tf.nn.relu))\n",
    "        layers.append(tf.keras.layers.Dropout(dropout))\n",
    "    layers.append(tf.keras.layers.Dense(output_class, activation=tf.nn.sigmoid))\n",
    "\n",
    "    model = tf.keras.models.Sequential(layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ee25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_train_model(\n",
    "    model,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    callbacks=None,\n",
    "    learning_rate=0.001,\n",
    "    metrics = None,\n",
    "    class_weight = None,\n",
    "    batch_size=1,\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "):\n",
    "    \"\"\"\n",
    "  Compiles and trains a given Keras model with the given data. \n",
    "  Assumes Adam optimizer for this implementation.\n",
    "  Assumes categorical cross-entropy loss.\n",
    "  \n",
    "  Arguments\n",
    "          learning_rate: Learning rate for the optimizer Adam\n",
    "          batch_size: Batch size for the mini-batch optimization\n",
    "          epochs: Number of epochs to train\n",
    "          verbose: Verbosity of the training process\n",
    "  \n",
    "  Returns\n",
    "  A copy of the model\n",
    "  \"\"\"\n",
    "\n",
    "    model_copy = model\n",
    "    model_copy.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    if callbacks != None:\n",
    "        model_copy.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weight,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "    else:\n",
    "        model_copy.fit(\n",
    "            x_train, y_train, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            class_weight=class_weight,\n",
    "            verbose=verbose\n",
    "        )\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eff52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingPlot(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    # This function is called when the training begins\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Initialize the lists for holding the logs, losses and metrics\n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.f1score = []\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "        self.logs = []\n",
    "    \n",
    "    # This function is called at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        Calculates and plots Precision, Recall, F1 score\n",
    "        \"\"\"\n",
    "        # Extract from the log\n",
    "        tp = logs.get('tp')\n",
    "        fp = logs.get('fp')\n",
    "        fn = logs.get('fn')\n",
    "        loss = logs.get('loss')\n",
    "        \n",
    "        m = self.model\n",
    "        preds = m.predict(X_train)\n",
    "        \n",
    "        # Calculate\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        f1score = 2*(precision*recall)/(precision+recall)    \n",
    "        \n",
    "        # Append the logs, losses and accuracies to the lists\n",
    "        self.logs.append(logs)\n",
    "        self.losses.append(loss)\n",
    "        self.f1score.append(f1score)\n",
    "        self.precision.append(precision)\n",
    "        self.recall.append(recall)\n",
    "        \n",
    "        # Plots every 5th epoch\n",
    "        if epoch > 0 and epoch%5==0:\n",
    "            \n",
    "            # Clear the previous plot\n",
    "            clear_output(wait=True)\n",
    "            N = np.arange(0, len(self.losses))\n",
    "            \n",
    "            # You can chose the style of your preference\n",
    "            plt.style.use(\"seaborn\")\n",
    "            \n",
    "            # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "            plt.figure(figsize=(10,3))\n",
    "            plt.title(\"Distribution of prediction probabilities at epoch no. {}\".format(epoch), \n",
    "                      fontsize=16)\n",
    "            plt.hist(preds, bins=50,edgecolor='k')\n",
    "            \n",
    "            plt.figure(figsize=(10,3))\n",
    "            plt.title(\"Loss over epoch\")\n",
    "            plt.plot(N, self.losses)\n",
    "            fig, ax = plt.subplots(1,3, figsize=(12,4))\n",
    "            ax = ax.ravel()\n",
    "            ax[0].plot(N, self.precision, label = \"Precision\", c='red')\n",
    "            ax[1].plot(N, self.recall, label = \"Recall\", c='red')\n",
    "            ax[2].plot(N, self.f1score, label = \"F1 score\", c='red')\n",
    "            ax[0].set_title(\"Precision at Epoch No. {}\".format(epoch))\n",
    "            ax[1].set_title(\"Recall at Epoch No. {}\".format(epoch))\n",
    "            ax[2].set_title(\"F1-score at Epoch No. {}\".format(epoch))\n",
    "            ax[0].set_xlabel(\"Epoch #\")\n",
    "            ax[1].set_xlabel(\"Epoch #\")\n",
    "            ax[2].set_xlabel(\"Epoch #\")\n",
    "            ax[0].set_ylabel(\"Precision\")\n",
    "            ax[1].set_ylabel(\"Recall\")\n",
    "            ax[2].set_ylabel(\"F1 score\")\n",
    "            ax[0].set_ylim(0,1)\n",
    "            ax[1].set_ylim(0,1)\n",
    "            ax[2].set_ylim(0,1)\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d73384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_features = 45\n",
    "n_informative = n_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6267d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = make_classification(n_samples=42000,\n",
    "                        n_features=n_features,\n",
    "                        n_informative=n_informative,\n",
    "                        n_redundant=0,\n",
    "                        n_classes=10,\n",
    "                        weights=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1],\n",
    "                        flip_y=0.05,\n",
    "                        class_sep=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba42e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features, target = d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5009d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('letters.csv')\n",
    "features = df.loc[:, df.columns != 'label']\n",
    "#X /= 255\n",
    "#X\n",
    "target = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43bb11e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel43</th>\n",
       "      <th>pixel44</th>\n",
       "      <th>pixel92</th>\n",
       "      <th>pixel124</th>\n",
       "      <th>pixel125</th>\n",
       "      <th>pixel126</th>\n",
       "      <th>pixel127</th>\n",
       "      <th>pixel128</th>\n",
       "      <th>pixel129</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel329</th>\n",
       "      <th>pixel351</th>\n",
       "      <th>pixel410</th>\n",
       "      <th>pixel411</th>\n",
       "      <th>pixel412</th>\n",
       "      <th>pixel413</th>\n",
       "      <th>pixel414</th>\n",
       "      <th>pixel415</th>\n",
       "      <th>pixel416</th>\n",
       "      <th>pixel417</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>192</td>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>255</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>157</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>248</td>\n",
       "      <td>253</td>\n",
       "      <td>176</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>253</td>\n",
       "      <td>229</td>\n",
       "      <td>133</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel43  pixel44  pixel92  pixel124  pixel125  pixel126  \\\n",
       "0          1        0        0        0         0         0         0   \n",
       "1          0        0        0        0       137       137       192   \n",
       "2          1        0        0        0         3       141       139   \n",
       "3          4        0        0        0         0         0         0   \n",
       "4          0        0        0        0       155       254       254   \n",
       "...      ...      ...      ...      ...       ...       ...       ...   \n",
       "41995      2        0        0        1       248       253       176   \n",
       "41996      0        0        0        0         0         0         0   \n",
       "41997      2        0        0        0       255       255       191   \n",
       "41998      2        0        0        0       255       128         0   \n",
       "41999      2        0        0      227       253       229       133   \n",
       "\n",
       "       pixel127  pixel128  pixel129  ...  pixel329  pixel351  pixel410  \\\n",
       "0             0         0         0  ...         0       254         0   \n",
       "1            86        72         1  ...       254         0         0   \n",
       "2             3         0         0  ...         0       184         0   \n",
       "3             0         0         0  ...         0         0        94   \n",
       "4           254       157        30  ...       253         0         0   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "41995        43         0         0  ...         0         0         0   \n",
       "41996         0         0       128  ...         0         0         0   \n",
       "41997         0         0         0  ...         0         0         0   \n",
       "41998         0         0         0  ...         0       255         0   \n",
       "41999        19         0         0  ...         0         0       253   \n",
       "\n",
       "       pixel411  pixel412  pixel413  pixel414  pixel415  pixel416  pixel417  \n",
       "0             0         0         0         0         0         0         0  \n",
       "1            75       254       254       254        17         0         0  \n",
       "2             0         0         0         0         0         0         0  \n",
       "3           255        69         0         0         0         0         0  \n",
       "4             0       223       253       253       253       129         0  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0         0         0  \n",
       "41996         0       255       255         0         0         0         0  \n",
       "41997         0         0         0         0         0         0         0  \n",
       "41998         0         0         0         0         0         0         0  \n",
       "41999       160         1         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 46 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85852bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pos = np.bincount(target)\n",
    "neg = np.bincount(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d848a801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "013b7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.5, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5960d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(target).astype('float32').reshape((-1,1))\n",
    "y_test = np.asarray(target).astype('float32').reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a411ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aeec3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3205628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(X_train.shape[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93a9028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "    tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46213f18",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30432/3061621131.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mweight_for_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mweight_for_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mweight_for_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbincount\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "counts = np.bincount(y_train)\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]\n",
    "weight_for_2 = 1.0 / counts[2]\n",
    "weight_for_3 = 1.0 / counts[3]\n",
    "weight_for_4 = 1.0 / counts[4]\n",
    "weight_for_5 = 1.0 / counts[5]\n",
    "weight_for_6 = 1.0 / counts[6]\n",
    "weight_for_7 = 1.0 / counts[7]\n",
    "weight_for_8 = 1.0 / counts[8]\n",
    "weight_for_9 = 1.0 / counts[9]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2, 3:weight_for_3, 4:weight_for_4, 5:weight_for_5, 6:weight_for_6, 7:weight_for_7, 8:weight_for_8, 9:weight_for_9}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a547ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_metrics = TrainingPlot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7de79167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m = build_classification_model(num_layers=5,\n",
    "                               architecture=[256,128,64,64,32],\n",
    "                               input_shape=input_shape,\n",
    "                               output_bias= initial_bias,\n",
    "                               output_class=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4179d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 45)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               11776     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,498\n",
      "Trainable params: 59,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2c90c64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.asarray(target).astype('float32').reshape((-1,1))\n",
    "#y_train.astype('float32').reshape((-1,1))\n",
    "#y_test.astype('float32').reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31219f30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 21000\n  y sizes: 42000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30432/2160561810.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m m = compile_train_model(model=m, \n\u001b[0m\u001b[0;32m      2\u001b[0m                         \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30432/3149857631.py\u001b[0m in \u001b[0;36mcompile_train_model\u001b[1;34m(model, x_train, y_train, callbacks, learning_rate, metrics, class_weight, batch_size, epochs, verbose)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         model_copy.fit(\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1653\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[0;32m   1654\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1655\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 21000\n  y sizes: 42000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "m = compile_train_model(model=m, \n",
    "                        x_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        metrics=metrics,\n",
    "                        class_weight=0.1,\n",
    "                        callbacks = [plot_metrics],\n",
    "                        batch_size=10,\n",
    "                        learning_rate=1e-3,\n",
    "                        epochs=100,\n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148d867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
